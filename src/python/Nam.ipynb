{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r\"../resources/IMDB Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tỷ lệ các nhãn:\n",
      "sentiment\n",
      "positive    50.0\n",
      "negative    50.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_counts = data['sentiment'].value_counts()\n",
    "\n",
    "label_ratios = label_counts / len(data) * 100 \n",
    "\n",
    "print(\"Tỷ lệ các nhãn:\")\n",
    "print(label_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ làm sạch dữ liệu đã cho bằng cách:\n",
    "- Xóa kí tự không phải chữ cái\n",
    "- Chuyển đổi kí tự về chữ thường\n",
    "- Tách từ: chia chuỗi thành danh sách các từ\n",
    "- Loại bỏ stopword và stemming\n",
    "    - Stemming là một kỹ thuật trong xử lý ngôn ngữ tự nhiên (NLP) nhằm giảm các từ về dạng gốc hoặc dạng cơ bản của chúng. Ví dụ:\n",
    "    Từ \"running\", \"runner\" và \"ran\" đều có gốc là \"run\".\n",
    "- Gép lại các từ thành chuỗi sau khi xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus = []\n",
    "for i in range(len(data)):\n",
    "    if isinstance(data[\"review\"].iloc[i], str): \n",
    "        review = re.sub('[^a-zA-Z]', ' ', data[\"review\"].iloc[i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "        review = [lemmatizer.lemmatize(word) for word in review]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    else:\n",
    "        corpus.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cho các text đã xử lý sang một cột mới trong data\n",
    "data['Processed_Text'] = corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển dữ liệu sang đặc trưng số sử dụng TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia data thành các tập train và test\n",
    "X = tfidf.fit_transform(data['Processed_Text']).toarray()\n",
    "y = data['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sử dụng mô hình MultinomialNB, BernoulliNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GaussianNB ---\n",
      "Accuracy: 0.8256\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83      5044\n",
      "    positive       0.82      0.83      0.82      4956\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "--- MultinomialNB ---\n",
      "Accuracy: 0.8603\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86      5044\n",
      "    positive       0.85      0.88      0.86      4956\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "--- BernoulliNB ---\n",
      "Accuracy: 0.8622\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86      5044\n",
      "    positive       0.85      0.88      0.86      4956\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Danh sách các mô hình\n",
    "models = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'BernoulliNB': BernoulliNB()\n",
    "}\n",
    "\n",
    "# Huấn luyện và đánh giá từng mô hình\n",
    "for model_name, model in models.items():\n",
    "    # Huấn luyện mô hình\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Tính độ chính xác và báo cáo phân loại\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # In kết quả\n",
    "    print(f'--- {model_name} ---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n' + '-' * 30 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Điều chỉnh siêu tham số cho mô hình Gaussian Naive Bayes\n",
    "Trong mô hình Gaussian Naive Bayes của scikit-learn, giá trị mặc định cho siêu tham số `var_smoothing` là $10^{-9}$. Ở đây ta sẽ thử khảo sát độ chính xác mô hình cho các giá trị khác nhau của siêu tham số này. Ta thấy giá trị tốt nhất là $10^{-2}$ tuy nhiên độ chính xác đạt được chênh lệch không đáng kể với giá trị mặc định.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "parameters = {'var_smoothing': np.logspace(0, -9, num=10)}  # Các giá trị var_smoothing\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "clf = GridSearchCV(gnb, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Best Parameters: {clf.best_params_}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "mean_accuracy = clf.cv_results_['mean_test_score'] \n",
    "var_smoothing_values = parameters['var_smoothing']  \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(var_smoothing_values, mean_accuracy, marker='o')\n",
    "plt.title('Model Accuracy vs. Variance Smoothing for GaussianNB')\n",
    "plt.xlabel('Variance Smoothing (var_smoothing)')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.xscale('log')  \n",
    "plt.xticks(var_smoothing_values, rotation=45)  \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8919\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89      5044\n",
      "    positive       0.88      0.91      0.89      4956\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test thử Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [4, 6, 8, 10, 12],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search with Cross Validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train the Random Forest model with the best parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
